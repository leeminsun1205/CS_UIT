{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YczE55EXiYx9",
    "outputId": "fec09d58-64a8-4fcb-e72e-dd6806784e68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium\n",
      "  Using cached gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\le mnh nhut\\anaconda3\\lib\\site-packages (from gymnasium) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\le mnh nhut\\anaconda3\\lib\\site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\le mnh nhut\\anaconda3\\lib\\site-packages (from gymnasium) (4.11.0)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
      "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Using cached gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
      "Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, gymnasium\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yhSyhfEy4XSD"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kHf1dAVKAcZm"
   },
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v1', render_mode=\"ansi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-6usoQHAmqh",
    "outputId": "93489122-4f7a-4319-b899-cb6238736629"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TimeLimit' object has no attribute 'P'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m env\u001b[38;5;241m.\u001b[39mP[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TimeLimit' object has no attribute 'P'"
     ]
    }
   ],
   "source": [
    "env.P[0][3] # Transition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wh7Su0h0AqQz",
    "outputId": "f36247bb-cf16-402a-fef8-b522dfccfb46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZ68w5bpBScC",
    "outputId": "84716bbc-e49d-4cd1-9022-4b6de67b8426"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWLnvY7VBvIZ"
   },
   "outputs": [],
   "source": [
    "def play(env, policy, render=False):\n",
    "    state, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = policy[state]\n",
    "        next_state, reward, done, info, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "        if render:\n",
    "            print(env.render())\n",
    "            time.sleep(0.5)\n",
    "            if not done:\n",
    "                display.clear_output(wait=True)\n",
    "        state = next_state\n",
    "\n",
    "    return (total_reward, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcuDDx6rC5YE",
    "outputId": "a27ca9fc-2d77-4780-99fa-ded5d412df1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_0 = np.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "play(env, policy_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJ1CJNPhDGPA",
    "outputId": "5f836a7e-2433-47a8-d5bc-1bd68408c388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "\u001b[41mH\u001b[0mFFG\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "policy_0 = np.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "play(env, policy_0, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdyjjtGZC9NX",
    "outputId": "2a725fc1-f650-4d4d-b742-94fdb0831670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_1 = np.asarray([0, 1, 1, 3, 1, 0, 2, 0, 1, 1, 2, 2, 3, 3, 1, 0])\n",
    "play(env, policy_1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tt0VhyMuDasc",
    "outputId": "362d2464-9186-4951-d603-0650917a8b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_2 = np.array([1, 1, 1, 3, 0, 1, 2, 3, 1, 1, 2, 3, 2, 2, 1, 3])\n",
    "play(env, policy_2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hp6qhRFJDxWR",
    "outputId": "95985327-c8ff-4fd4-dab9-d3e424403b56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 27)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_3 = np.array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0])\n",
    "play(env, policy_3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JU8Q1qMxD6Po"
   },
   "outputs": [],
   "source": [
    "def play_multiple_times(env, policy, max_episodes):\n",
    "    success = 0\n",
    "    list_of_steps = []\n",
    "    for i in range(max_episodes):\n",
    "        total_reward, steps = play(env, policy)\n",
    "\n",
    "        if total_reward > 0:\n",
    "            success += 1\n",
    "            list_of_steps.append(steps)\n",
    "\n",
    "    print(f'Number of successes: {success}/{max_episodes}')\n",
    "    print(f'Average number of steps: {np.mean(list_of_steps)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G427z17PEmjQ",
    "outputId": "767787ee-a988-4119-a7d7-c0b8fca5cd45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successes: 0/1000\n",
      "Average number of steps: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "policy_0 = np.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "play_multiple_times(env, policy_0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1bkhaFdDmj_",
    "outputId": "cb80ff3f-206c-4588-c32b-a70787a5fcc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successes: 45/1000\n",
      "Average number of steps: 11.066666666666666\n"
     ]
    }
   ],
   "source": [
    "policy_1 = np.asarray([0, 1, 1, 3, 1, 0, 2, 0, 1, 1, 2, 2, 3, 3, 1, 0])\n",
    "play_multiple_times(env, policy_1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ZYhsb_VEtuR",
    "outputId": "91e5b9fc-a4d1-4bbe-ec54-beff45b4ff26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successes: 107/1000\n",
      "Average number of steps: 14.57943925233645\n"
     ]
    }
   ],
   "source": [
    "policy_2 = np.array([1, 1, 1, 3, 0, 1, 2, 3, 1, 1, 2, 3, 2, 2, 1, 3])\n",
    "play_multiple_times(env, policy_2, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvvHdMesEzTH",
    "outputId": "ab249a9d-2c70-4b83-c4ca-960955151d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successes: 788/1000\n",
      "Average number of steps: 44.67005076142132\n"
     ]
    }
   ],
   "source": [
    "policy_3 = np.array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0])\n",
    "play_multiple_times(env, policy_3, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSomNpxJE5lP"
   },
   "outputs": [],
   "source": [
    "def policy_evaluation(env, policy, max_iters=500, gamma=0.9):\n",
    "    # Initialize the values of all states to be 0\n",
    "    v_values = np.zeros(env.observation_space.n)\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        prev_v_values = np.copy(v_values)\n",
    "\n",
    "        # Update the value of each state\n",
    "        for state in range(env.observation_space.n):\n",
    "            action = policy[state]\n",
    "\n",
    "            # Compute the q-value of the action\n",
    "            q_value = 0\n",
    "            for prob, next_state, reward, done in env.P[state][action]:\n",
    "                q_value += prob * (reward + gamma * prev_v_values[next_state])\n",
    "\n",
    "            v_values[state] = q_value # update v-value\n",
    "\n",
    "        # Check convergence\n",
    "        if np.all(np.isclose(v_values, prev_v_values)):\n",
    "            print(f'Converged at {i}-th iteration.')\n",
    "            break\n",
    "\n",
    "    return v_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7IhqEOgGkQX",
    "outputId": "dedb79ed-b2e0-49bb-aa27-66a49b4a7287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at 0-th iteration.\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "policy_0 = np.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "v_values_0 = policy_evaluation(env, policy_0)\n",
    "print(v_values_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zMjJKI3GGrsN",
    "outputId": "f44e8c8b-ae3a-4c57-c541-06b0528c3f30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at 48-th iteration.\n",
      "[0.01904157 0.01519815 0.03161906 0.02371389 0.02538879 0.\n",
      " 0.06648515 0.         0.05924054 0.13822794 0.18999823 0.\n",
      " 0.         0.21152109 0.56684236 0.        ]\n"
     ]
    }
   ],
   "source": [
    "policy_1 = np.asarray([0, 1, 1, 3, 1, 0, 2, 0, 1, 1, 2, 2, 3, 3, 1, 0])\n",
    "v_values_1 = policy_evaluation(env, policy_1)\n",
    "print(v_values_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-26M77nEfcV",
    "outputId": "884ec971-d167-47c5-9a85-0aae689f0584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(v_values_1 >= v_values_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l49O1N8QG0S2",
    "outputId": "eb8d230c-4541-4b9a-b79d-bcae5820aea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at 53-th iteration.\n",
      "[0.02889625 0.01951972 0.03616977 0.0271268  0.04790519 0.\n",
      " 0.07391985 0.         0.08288277 0.19339319 0.21022995 0.\n",
      " 0.         0.35153135 0.62684674 0.        ]\n"
     ]
    }
   ],
   "source": [
    "policy_2 = np.array([1, 1, 1, 3, 0, 1, 2, 3, 1, 1, 2, 3, 2, 2, 1, 3])\n",
    "v_values_2 = policy_evaluation(env, policy_2)\n",
    "print(v_values_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22pRvreGE3Yt",
    "outputId": "42083d43-0b5a-4c11-c522-0a50f088958a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(v_values_2 >= v_values_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTYYFq6BEXDd",
    "outputId": "6c828ca5-3c5d-4bd0-e710-86fc649022c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at 80-th iteration.\n",
      "[0.06888666 0.06141097 0.07440714 0.05580443 0.09185068 0.\n",
      " 0.11220679 0.         0.14543323 0.24749485 0.29961611 0.\n",
      " 0.         0.37993438 0.63901935 0.        ]\n"
     ]
    }
   ],
   "source": [
    "policy_3 = np.array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0])\n",
    "v_values_3 = policy_evaluation(env, policy_3)\n",
    "print(v_values_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zcEfU3NYE7xN",
    "outputId": "7d69edaf-8252-4827-fb70-01d51c3d8382"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(v_values_3 >= v_values_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uh4akjMSHJBF"
   },
   "outputs": [],
   "source": [
    "def value_iteration(env, max_iters=500, gamma=0.9):\n",
    "    # initialize\n",
    "    v_values = np.zeros(env.observation_space.n)\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        prev_v_values = np.copy(v_values)\n",
    "\n",
    "        # update the v-value for each state\n",
    "        for state in range(env.observation_space.n):\n",
    "            q_values = []\n",
    "\n",
    "            # compute the q-value for each action that we can perform at the state\n",
    "            for action in range(env.action_space.n):\n",
    "                q_value = 0\n",
    "                # loop through each possible outcome\n",
    "                for prob, next_state, reward, done in env.P[state][action]:\n",
    "                    q_value += prob * (reward + gamma * prev_v_values[next_state])\n",
    "\n",
    "                q_values.append(q_value)\n",
    "\n",
    "            # select the max q-values\n",
    "            best_action = np.argmax(q_values)\n",
    "            v_values[state] = q_values[best_action]\n",
    "\n",
    "        # check convergence\n",
    "        if np.all(np.isclose(v_values, prev_v_values)):\n",
    "            print(f'Converged at {i}-th iteration.')\n",
    "            break\n",
    "\n",
    "    return v_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8xAljw7VuMP",
    "outputId": "79eef480-c6a6-4182-b1a1-e90a9e113373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at 79-th iteration.\n"
     ]
    }
   ],
   "source": [
    "optimal_v_values = value_iteration(env, max_iters=500, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7g9VA3lV2WW",
    "outputId": "8dddd4d5-2e31-4aad-c9ca-a9843742d5bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06888615, 0.06141054, 0.07440682, 0.05580409, 0.09185022,\n",
       "       0.        , 0.11220663, 0.        , 0.14543286, 0.2474946 ,\n",
       "       0.29961593, 0.        , 0.        , 0.3799342 , 0.63901926,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_v_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jb0an7gaV39e"
   },
   "outputs": [],
   "source": [
    "def policy_extraction(env, v_values, gamma=0.9):\n",
    "    # initialize\n",
    "    policy = np.zeros(env.observation_space.n, dtype=np.int32)\n",
    "\n",
    "    # loop through each state in the environment\n",
    "    for state in range(env.observation_space.n):\n",
    "        q_values = []\n",
    "        # loop through each action\n",
    "        for action in range(env.action_space.n):\n",
    "            q_value = 0\n",
    "            # loop each possible outcome\n",
    "            for prob, next_state, reward, done in env.P[state][action]:\n",
    "                q_value += prob * (reward + gamma * v_values[next_state])\n",
    "\n",
    "            q_values.append(q_value)\n",
    "\n",
    "        # select the best action\n",
    "        best_action = np.argmax(q_values)\n",
    "        policy[state] = best_action\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TGCF4G7XErH"
   },
   "outputs": [],
   "source": [
    "optimal_policy = policy_extraction(env, optimal_v_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qkHYtfm4qikV",
    "outputId": "186d39fa-54b2-4b2b-a69c-d0969f53a3eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Ww12Uh5qCUb",
    "outputId": "aab50131-9b1f-4bc0-a6fb-f14ce9ccde37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play(env, optimal_policy, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-m4ZqWZXKqG",
    "outputId": "caffbded-cdfd-40ee-cbe6-0c602cf5e87b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successes: 777/1000\n",
      "Average number of steps: 43.18532818532819\n"
     ]
    }
   ],
   "source": [
    "play_multiple_times(env, optimal_policy, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mg0TcNPAyFaY"
   },
   "source": [
    "## **BÀI LÀM**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eAkEH9FzF-X"
   },
   "source": [
    "# **Policy Iteration**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6L3JVnl09hF"
   },
   "outputs": [],
   "source": [
    "def policy_iteration(env, max_iters=500, gamma=0.9):\n",
    "    # Initialize the policy randomly and the value function to zeros\n",
    "    policy = np.random.randint(env.action_space.n, size= (env.observation_space.n))\n",
    "    v_values = np.zeros(env.observation_space.n)\n",
    "\n",
    "    for i in range(max_iters):\n",
    "      # Copy the current policy to check for convergence later\n",
    "      prev_policy= np.copy(policy)\n",
    "      # Policy Evaluation\n",
    "      for j in range(max_iters):\n",
    "          prev_v_values = np.copy(v_values)\n",
    "          # Update the value of each state\n",
    "          for state in range(env.observation_space.n):\n",
    "              action = policy[state]\n",
    "              # Compute the q-value of the action\n",
    "              q_value = 0\n",
    "              for prob, next_state, reward, done in env.P[state][action]:\n",
    "                  q_value += prob * (reward + gamma * prev_v_values[next_state])\n",
    "              v_values[state] = q_value # update v-value\n",
    "          # Check convergence\n",
    "          if np.all(np.isclose(v_values, prev_v_values)):\n",
    "              break\n",
    "      # Policy xtraction\n",
    "      for state in range(env.observation_space.n):\n",
    "          q_values = []\n",
    "          # loop through each action\n",
    "          for action in range(env.action_space.n):\n",
    "              q_value = 0\n",
    "              # loop each possible outcome\n",
    "              for prob, next_state, reward, done in env.P[state][action]:\n",
    "                  q_value += prob * (reward + gamma * v_values[next_state])\n",
    "              q_values.append(q_value)\n",
    "          # select the best action\n",
    "          best_action = np.argmax(q_values)\n",
    "          policy[state] = best_action\n",
    "      # Check if the policy has converged\n",
    "      if np.all(prev_policy==policy):\n",
    "          print(f'Converged at {i}-th iteration.')\n",
    "          break\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfOrua43zK8Q"
   },
   "source": [
    "# Thêm môi trường 'FrozenLake8x8-v1' và 'Taxi-v3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEoChKi4FYbj"
   },
   "outputs": [],
   "source": [
    "#tạo môi trường 'FrozenLake8x8-v1'\n",
    "env1 = gym.make('FrozenLake8x8-v1', render_mode=\"ansi\")\n",
    "#tạo môi trường 'Taxi-v3'\n",
    "env2 = gym.make('Taxi-v3', render_mode=\"ansi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acxEg0d_zy_T"
   },
   "source": [
    "# Tính thời gian chạy trung bình của các môi trường với **Value Iteration** (bao gồm Policy Extraction)\n",
    "\n",
    "*   Note: Làm như vậy để đảm bảo Value Iteration được đánh giá cùng 1 tiêu chí với Policy Iteration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJ_Ju02y9b_H",
    "outputId": "084d26cb-0718-4e39-a192-264c2e7dbfc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n",
      "Converged at 79-th iteration.\n"
     ]
    }
   ],
   "source": [
    "#'FrozenLake-v1'\n",
    "start=time.time()\n",
    "for i in range(20):\n",
    "  optimal_v_values = value_iteration(env)\n",
    "  policy_extraction(env, optimal_v_values)\n",
    "end=time.time()\n",
    "avg_time_v=(end-start)/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m1pYgYB8FwAm",
    "outputId": "9d305a76-8d7f-4454-c9cb-6def1dc5f3a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 117-th iteration.\n"
     ]
    }
   ],
   "source": [
    "#'FrozenLake8x8-v1'\n",
    "start=time.time()\n",
    "for i in range(20):\n",
    "  optimal_v_values = value_iteration(env1)\n",
    "  policy_extraction(env1, optimal_v_values)\n",
    "end=time.time()\n",
    "avg_time_v1=(end-start)/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QM3FRtFFvw-",
    "outputId": "1ffc427b-2e56-415f-b9d0-b83d88ac9995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Converged at 116-th iteration.\n"
     ]
    }
   ],
   "source": [
    "#'Taxi-v3'\n",
    "for i in range(20):\n",
    "  optimal_v_values = value_iteration(env2)\n",
    "  policy_extraction(env2, optimal_v_values)\n",
    "end=time.time()\n",
    "avg_time_v2=(end-start)/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNze5CmKGeDZ"
   },
   "outputs": [],
   "source": [
    "#lưu thời gian chạy trung bình của mỗi môi trường\n",
    "avg_time_v_values=np.array([avg_time_v, avg_time_v1, avg_time_v2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbrAhEBe3beq"
   },
   "source": [
    "# Tính thời gian chạy trung bình của các môi trường với **Policy Iteration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x58xZ6Gkp0sP",
    "outputId": "f5180324-a676-4ca4-bf68-6abde7c742c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at 1-th iteration.\n",
      "Converged at 3-th iteration.\n",
      "Converged at 5-th iteration.\n",
      "Converged at 1-th iteration.\n",
      "Converged at 2-th iteration.\n",
      "Converged at 5-th iteration.\n",
      "Converged at 5-th iteration.\n",
      "Converged at 4-th iteration.\n",
      "Converged at 3-th iteration.\n",
      "Converged at 3-th iteration.\n",
      "Converged at 2-th iteration.\n",
      "Converged at 3-th iteration.\n",
      "Converged at 5-th iteration.\n",
      "Converged at 2-th iteration.\n",
      "Converged at 3-th iteration.\n",
      "Converged at 2-th iteration.\n",
      "Converged at 3-th iteration.\n",
      "Converged at 3-th iteration.\n",
      "Converged at 5-th iteration.\n",
      "Converged at 3-th iteration.\n"
     ]
    }
   ],
   "source": [
    "#'FrozenLake-v1'\n",
    "start=time.time()\n",
    "for i in range(20):\n",
    "  policy_iteration(env)\n",
    "end=time.time()\n",
    "avg_time_p=(end-start)/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U8CuU2YkILBB",
    "outputId": "511f75fa-e9c2-4dec-c1a1-9ad321e4533d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at 2-th iteration.\n",
      "Converged at 2-th iteration.\n",
      "Converged at 8-th iteration.\n",
      "Converged at 6-th iteration.\n",
      "Converged at 8-th iteration.\n",
      "Converged at 6-th iteration.\n",
      "Converged at 8-th iteration.\n",
      "Converged at 8-th iteration.\n",
      "Converged at 9-th iteration.\n",
      "Converged at 4-th iteration.\n",
      "Converged at 9-th iteration.\n",
      "Converged at 8-th iteration.\n",
      "Converged at 4-th iteration.\n",
      "Converged at 8-th iteration.\n",
      "Converged at 4-th iteration.\n",
      "Converged at 3-th iteration.\n",
      "Converged at 9-th iteration.\n",
      "Converged at 7-th iteration.\n",
      "Converged at 8-th iteration.\n",
      "Converged at 2-th iteration.\n"
     ]
    }
   ],
   "source": [
    "#'FrozenLake8x8-v1'\n",
    "start=time.time()\n",
    "for i in range(20):\n",
    "  policy_iteration(env1)\n",
    "end=time.time()\n",
    "avg_time_p1=(end-start)/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gjvi4XqwIK0Y",
    "outputId": "927dd10f-4b7a-4646-bb8e-8c8efd1446e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at 16-th iteration.\n",
      "Converged at 17-th iteration.\n",
      "Converged at 17-th iteration.\n",
      "Converged at 16-th iteration.\n",
      "Converged at 17-th iteration.\n",
      "Converged at 17-th iteration.\n",
      "Converged at 15-th iteration.\n",
      "Converged at 16-th iteration.\n",
      "Converged at 17-th iteration.\n",
      "Converged at 16-th iteration.\n",
      "Converged at 17-th iteration.\n",
      "Converged at 17-th iteration.\n",
      "Converged at 17-th iteration.\n",
      "Converged at 16-th iteration.\n",
      "Converged at 15-th iteration.\n",
      "Converged at 17-th iteration.\n",
      "Converged at 16-th iteration.\n",
      "Converged at 16-th iteration.\n",
      "Converged at 16-th iteration.\n",
      "Converged at 17-th iteration.\n"
     ]
    }
   ],
   "source": [
    "#'Taxi-v3'\n",
    "start=time.time()\n",
    "for i in range(20):\n",
    "  policy_iteration(env2)\n",
    "end=time.time()\n",
    "avg_time_p2=(end-start)/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uU4155CGIsLc"
   },
   "outputs": [],
   "source": [
    "#lưu thời gian chạy trung bình của mỗi môi trường\n",
    "avg_time_policy=np.array([avg_time_p, avg_time_p1, avg_time_p2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hU_xJzwv5e53"
   },
   "source": [
    "# So sánh **Value Iteration** và **Policy Iteration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lU4kuqyBmMTQ",
    "outputId": "b7230daa-3180-4260-de9d-854fd458e7f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Iteration\n",
      "Converged at 79-th iteration.\n",
      "Converged at 117-th iteration.\n",
      "Converged at 116-th iteration.\n",
      "Policy Iteration\n",
      "Converged at 3-th iteration.\n",
      "Converged at 8-th iteration.\n",
      "Converged at 16-th iteration.\n"
     ]
    }
   ],
   "source": [
    "# lưu các chính sách tối ưu dùng Value Iteration\n",
    "print('Value Iteration')\n",
    "optimal_v = value_iteration(env)\n",
    "optimal_policy_v = policy_extraction(env, optimal_v)\n",
    "optimal_v1 = value_iteration(env1)\n",
    "optimal_policy_v1 = policy_extraction(env1, optimal_v1)\n",
    "optimal_v2 = value_iteration(env2)\n",
    "optimal_policy_v2 = policy_extraction(env2, optimal_v2)\n",
    "# lưu các chính sách tối dùng Policy Iteration\n",
    "print('Policy Iteration')\n",
    "optimal_policy_p = policy_iteration(env)\n",
    "optimal_policy_p1 = policy_iteration(env1)\n",
    "optimal_policy_p2 = policy_iteration(env2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuKDBuas6vQg"
   },
   "source": [
    "**Nhận xét:** Ta thấy *Policy Iteration* hội tụ nhanh hơn *Value Iteration*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nALfq_n8qRsY",
    "outputId": "7b6afe49-3edc-4c04-8df9-9543374c3c28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-FrozenLake-v1 với value iteration\n",
      "Number of successes: 756/1000\n",
      "Average number of steps: 43.198412698412696\n",
      "-FrozenLake-v1 với policy iteration\n",
      "Number of successes: 761/1000\n",
      "Average number of steps: 43.60578186596583\n",
      "\n",
      "-FrozenLake8x8-v1 với value iteration\n",
      "Number of successes: 736/1000\n",
      "Average number of steps: 73.9836956521739\n",
      "-FrozenLake8x8-v1 với policy iteration\n",
      "Number of successes: 754/1000\n",
      "Average number of steps: 73.44429708222812\n",
      "\n",
      "-Taxi-v3 với value iteration\n",
      "Number of successes: 1000/1000\n",
      "Average number of steps: 13.083\n",
      "-Taxi-v3 với policy iteration\n",
      "Number of successes: 1000/1000\n",
      "Average number of steps: 13.098\n"
     ]
    }
   ],
   "source": [
    "print('-FrozenLake-v1 với value iteration')\n",
    "\n",
    "play_multiple_times(env, optimal_policy_v, 1000)\n",
    "\n",
    "print('-FrozenLake-v1 với policy iteration')\n",
    "\n",
    "play_multiple_times(env, optimal_policy_p, 1000)\n",
    "\n",
    "print('\\n-FrozenLake8x8-v1 với value iteration')\n",
    "\n",
    "play_multiple_times(env1, optimal_policy_v1, 1000)\n",
    "\n",
    "print('-FrozenLake8x8-v1 với policy iteration')\n",
    "\n",
    "play_multiple_times(env1, optimal_policy_p1, 1000)\n",
    "\n",
    "print('\\n-Taxi-v3 với value iteration')\n",
    "\n",
    "play_multiple_times(env2, optimal_policy_v2, 1000)\n",
    "\n",
    "print('-Taxi-v3 với policy iteration')\n",
    "\n",
    "play_multiple_times(env2, optimal_policy_p2, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPyHs5RH6TA9"
   },
   "source": [
    "**Nhận xét:** Ta thấy cả *Value Iteration* và *Policy Iteration* có số bước đi trung bình gần như nhau và đều cho kết quả tối ưu với các môi trường"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u07qoi0GKDEY",
    "outputId": "7d0b084f-c2af-4a45-f484-5113c3337474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian chạy trung bình của Value Iteration là:  2.549207059542338\n"
     ]
    }
   ],
   "source": [
    "print(\"Thời gian chạy trung bình của Value Iteration là: \", avg_time_v_values.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrQ4EcuQKWZB",
    "outputId": "2cf6ea90-0b36-4510-db9f-c76f0355acd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian chạy trung bình của Policy Iteration là:  1.3642276525497437\n"
     ]
    }
   ],
   "source": [
    "print(\"Thời gian chạy trung bình của Policy Iteration là: \", avg_time_policy.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PWHvN637mQO"
   },
   "source": [
    "**Nhận xét:** Ta thấy *Policy Iteration* có thời gian chạy trung bình nhanh hơn *Value Iteration*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
