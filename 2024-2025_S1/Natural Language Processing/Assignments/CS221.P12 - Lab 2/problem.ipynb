{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T10:48:22.346068Z",
     "iopub.status.busy": "2024-10-03T10:48:22.343935Z",
     "iopub.status.idle": "2024-10-03T10:48:27.453439Z",
     "shell.execute_reply": "2024-10-03T10:48:27.450518Z"
    },
    "executionInfo": {
     "elapsed": 1293,
     "status": "ok",
     "timestamp": 1711646935952,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "48UH6zEyaSc8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LE MNH NHUT\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cosine\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T10:48:27.468669Z",
     "iopub.status.busy": "2024-10-03T10:48:27.463541Z",
     "iopub.status.idle": "2024-10-03T10:48:27.483205Z",
     "shell.execute_reply": "2024-10-03T10:48:27.480733Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1711646804012,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "ZVdb62fRyhTn"
   },
   "outputs": [],
   "source": [
    "def load_vocab_dict(path: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Reads a vocabulary list from a file and creates a dictionary mapping each word to its index.\n",
    "\n",
    "    Args:\n",
    "        path (str): The file path to the vocabulary list.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], Dict[str, int]]: A tuple containing the list of vocabulary words and a dictionary\n",
    "                                          mapping each word to its index.\n",
    "    \"\"\"\n",
    "    vocab = open(path).read().strip().split('\\n')\n",
    "    return vocab, {word: idx for idx, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T10:48:27.495654Z",
     "iopub.status.busy": "2024-10-03T10:48:27.493609Z",
     "iopub.status.idle": "2024-10-03T10:48:27.505206Z",
     "shell.execute_reply": "2024-10-03T10:48:27.502686Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1711646804013,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "hkJ7fQifz532"
   },
   "outputs": [],
   "source": [
    "def read_corpus(path: str) -> List[str]:\n",
    "    \"\"\"Reads the corpus from a file, excluding the last empty entry if the file ends with a newline.\n",
    "\n",
    "    Args:\n",
    "        path (str): The file path to the corpus.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of strings, each representing a line from the file.\n",
    "    \"\"\"\n",
    "    return open(path).read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T10:48:27.515749Z",
     "iopub.status.busy": "2024-10-03T10:48:27.513275Z",
     "iopub.status.idle": "2024-10-03T10:48:27.538482Z",
     "shell.execute_reply": "2024-10-03T10:48:27.535970Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1711646804013,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "_cgReXf9FIl2"
   },
   "outputs": [],
   "source": [
    "def counting(corpus: List[str], V: List[str], V_C: List[str], V_set: Dict[str, int], V_C_set: Dict[str, int], w: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates a co-occurrence (counting) matrix from the given corpus, considering specified vocabularies and a window size.\n",
    "\n",
    "    Args:\n",
    "        corpus (List[str]): The corpus as a list of sentences.\n",
    "        V (List[str]): The list of vocabulary words.\n",
    "        V_C (List[str]): The list of context vocabulary words.\n",
    "        V_set (Dict[str, int]): A dictionary mapping vocabulary words to their indices.\n",
    "        V_C_set (Dict[str, int]): A dictionary mapping context vocabulary words to their indices.\n",
    "        w (int): The window size for context.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 2D NumPy array representing the co-occurrence matrix with dimensions (len(V), len(V_C)).\n",
    "    \"\"\"\n",
    "    # Initialize the matrix to hold word vectors\n",
    "    C = np.zeros((len(V), len(V_C)), dtype=float)\n",
    "\n",
    "    for line in tqdm(corpus): # Iterate over each word in the original dataset\n",
    "        # Append start and end tokens to the sentence\n",
    "        words = ['<s>'] + line.split(' ') + ['</s>']\n",
    "        length = len(words)\n",
    "\n",
    "        for idx, word in enumerate(words): # Iterate over each word in the current sentence\n",
    "            # Skip '<s>' and '</s>', as they are not real words\n",
    "            if idx > 0 and idx < length - 1 and word in V_set:\n",
    "                context_words = words[max(idx-w,0):idx] + words[idx+1:min(idx+w+1,length)]\n",
    "\n",
    "                # Constructs a co-occurrence matrix by iterating over context words\n",
    "                # within a specified range and increments counts in the matrix\n",
    "                # for each word-context pair found in a predefined vocabulary.\n",
    "                # It quantifies the relationship between words and their context in a corpus,\n",
    "                # essential for analyzing word associations.\n",
    "\n",
    "                ### BEGIN SOLUTION\n",
    "                for c_w in context_words:\n",
    "                    if c_w in V_C_set:\n",
    "                        C[V_set[word], V_C_set[c_w]] += 1\n",
    "                \n",
    "                \n",
    "                ### END SOLUTION\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T10:48:27.553456Z",
     "iopub.status.busy": "2024-10-03T10:48:27.548978Z",
     "iopub.status.idle": "2024-10-03T10:48:27.569724Z",
     "shell.execute_reply": "2024-10-03T10:48:27.567269Z"
    },
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1711646943804,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "_KAL4m9SDyKA"
   },
   "outputs": [],
   "source": [
    "def eval_word_similarity(C: np.ndarray, V_set: Dict[str, int], path: str) -> float:\n",
    "    \"\"\"\n",
    "    Evaluates word similarity by comparing a calculated similarity matrix against a gold standard dataset.\n",
    "\n",
    "    Args:\n",
    "        C (np.ndarray): A 2D NumPy array where rows represent words and columns represent their vector embeddings.\n",
    "        V_set (Dict[str, int]): A dictionary mapping words to their indices in the matrix C.\n",
    "        path (str): The file path to the gold standard dataset.\n",
    "\n",
    "    Returns:\n",
    "        float: The Spearman correlation coefficient between the gold standard similarity scores and the calculated scores.\n",
    "    \"\"\"\n",
    "    # Read the gold standard data, skipping the header and the last empty line if present\n",
    "    gold = [line.split('\\t') for line in open(path).read().strip().split('\\n')[1:]]\n",
    "\n",
    "    # Prepare gold scores and similarity scores\n",
    "    y = [float(line[2]) for line in gold]  # Extract gold standard similarity scores\n",
    "    x = [\n",
    "        1 - cosine(C[V_set[word_1], :], C[V_set[word_2], :]) if word_1 in V_set and word_2 in V_set else 0\n",
    "        for word_1, word_2, _ in gold\n",
    "    ]\n",
    "\n",
    "    # Calculate and return Spearman correlation\n",
    "    return stats.spearmanr(x, y, axis=None).correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-03T10:48:27.579481Z",
     "iopub.status.busy": "2024-10-03T10:48:27.578604Z",
     "iopub.status.idle": "2024-10-03T10:51:38.611302Z",
     "shell.execute_reply": "2024-10-03T10:51:38.608218Z"
    },
    "executionInfo": {
     "elapsed": 114004,
     "status": "ok",
     "timestamp": 1711646918013,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "tKH1dmT2D8V4",
    "outputId": "cbca5f46-8a0f-4da5-9a89-51835eb1dcf8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 997898/997898 [02:04<00:00, 7999.68it/s] \n"
     ]
    }
   ],
   "source": [
    "# Read the main vocabulary and its indices from a file,\n",
    "# creating a list of words (V) and a dictionary mapping words to indices (V_set).\n",
    "V, V_set = load_vocab_dict('./data/main_words.txt')\n",
    "\n",
    "# Read the context vocabulary and its indices from a separate file,\n",
    "# creating a list of context words (V_C) and a dictionary mapping these words to indices (V_C_set).\n",
    "V_C, V_C_set = load_vocab_dict('./data/context_words.txt')\n",
    "\n",
    "# Read the corpus from a text file, creating a list where each item represents a document or line in the corpus.\n",
    "corpus = read_corpus('./data/corpus.txt')\n",
    "\n",
    "# Generate a co-occurrence (counting) matrix from the corpus using the main and context vocabularies.\n",
    "# The window size 'w=3' indicates the context range around each target word to consider for co-occurrences.\n",
    "C = counting(corpus, V, V_C, V_set, V_C_set, w=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-03T10:51:38.621820Z",
     "iopub.status.busy": "2024-10-03T10:51:38.620997Z",
     "iopub.status.idle": "2024-10-03T10:51:38.762163Z",
     "shell.execute_reply": "2024-10-03T10:51:38.759505Z"
    },
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1711646948109,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "3VvhpytXBs1A",
    "outputId": "24707dd3-b3ed-472d-8b03-52fee9edd664"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23223229343659896"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_word_similarity(C, V_set, './data/men.txt')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-03T10:51:38.772879Z",
     "iopub.status.busy": "2024-10-03T10:51:38.771308Z",
     "iopub.status.idle": "2024-10-03T10:51:38.838339Z",
     "shell.execute_reply": "2024-10-03T10:51:38.835716Z"
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1711646949884,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "YNde13fFBxMz",
    "outputId": "f8b94b4c-a48d-4102-9f79-9d398fe9a9bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LE MNH NHUT\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\spatial\\distance.py:636: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06530866131712797"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_word_similarity(C, V_set, './data/simlex-999.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T10:51:38.849153Z",
     "iopub.status.busy": "2024-10-03T10:51:38.847556Z",
     "iopub.status.idle": "2024-10-03T10:54:48.117110Z",
     "shell.execute_reply": "2024-10-03T10:54:48.113725Z"
    },
    "executionInfo": {
     "elapsed": 22862,
     "status": "ok",
     "timestamp": 1711646974553,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "vAn1zXmOE6zT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LE MNH NHUT\\AppData\\Local\\Temp\\ipykernel_26588\\1076850086.py:33: RuntimeWarning: divide by zero encountered in log2\n",
      "  pmi_matrix = np.log2(p_xy / (np.outer(p_x, p_y) + 4.421052631578947e-09)) #4e-9\n"
     ]
    }
   ],
   "source": [
    "def improve_C(C: np.ndarray) -> np.ndarray:\n",
    "# def improve_C(C: np.ndarray, n_c, r_s) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Improves the input co-occurrence matrix C using your specified technique.\n",
    "\n",
    "    Args:\n",
    "        C (np.ndarray): The co-occurrence matrix with shape (len(V), len(V_C)), where len(V) is the number of\n",
    "                        vocabulary words, and len(V_C) is the number of context words.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A matrix of shape (len(V), arbitrary_dimension).\n",
    "    \"\"\"\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import NMF\n",
    "\n",
    "    # import gensim\n",
    "    # from gensim.models import Word2Vec\n",
    "    # from sklearn.decomposition import TruncatedSVD\n",
    "    \n",
    "    \n",
    "    total = np.sum(C)\n",
    "    word_count = np.sum(C, axis=1)\n",
    "    context_count = np.sum(C, axis=0)\n",
    "    \n",
    "    p_xy = C / total\n",
    "    p_x = word_count / total\n",
    "    p_y = context_count / total\n",
    "    \n",
    "    pmi_matrix = np.log2(p_xy / (np.outer(p_x, p_y) + 4.421052631578947e-09)) #4e-9\n",
    "    pmi_matrix[p_xy == 0] = 0 \n",
    "    pmi_matrix -= 0.5263157894736843\n",
    "    \n",
    "    PPMI = np.maximum(pmi_matrix, 0)\n",
    "    \n",
    "    NPMI = (PPMI - np.log2(p_y)) / - np.log2(p_xy.shape[0])  \n",
    "    \n",
    "    \n",
    "    C_improved = (NPMI + 0.2894736842105263) / np.linalg.norm(NPMI + 0.04789473684210527, axis=1, keepdims=True) # 0.27, 0.01\n",
    "    \n",
    "    C_improved = StandardScaler().fit_transform(C_improved)\n",
    "    \n",
    "    C_improved = PCA(n_components=1160, random_state = 6308).fit_transform(C_improved) - 0.181 #6308\n",
    "    \n",
    "    # C_improved = StandardScaler().fit_transform(C_improved)\n",
    "\n",
    "    return C_improved\n",
    "    ### END SOLUTION\n",
    "\n",
    "C_improved = improve_C(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-03T10:54:48.130158Z",
     "iopub.status.busy": "2024-10-03T10:54:48.128941Z",
     "iopub.status.idle": "2024-10-03T10:54:48.267361Z",
     "shell.execute_reply": "2024-10-03T10:54:48.264713Z"
    },
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1711647191396,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "soX6cOUlHKL1",
    "outputId": "4def8b54-8107-4b9f-d03a-ba94821ee3ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "men: 0.5800859348358763\n",
      "simlex: 0.29251701110283584\n",
      "avg: 0.43630147296935606\n"
     ]
    }
   ],
   "source": [
    "men_p = eval_word_similarity(C_improved, V_set, './data/men.txt')   \n",
    "simlex_p = eval_word_similarity(C_improved, V_set, './data/simlex-999.txt')\n",
    "print(f'men: {men_p}', f'simlex: {simlex_p}', f'avg: {(men_p + simlex_p)/2}', sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
